# Object Recognition

# Object Recognition

- Problems
    - Going from a 3D world, to a 2D representation of vision (retina and the eyes), back to a 3D world represented in your consciousness and brain??
    - The ability to recognize objects despite differences in viewpoint and orientation, how do we know this is the *same object* when the retinal image is totally different?
    - Distintinguising objects that are identical, how do we know that different objects are independent objects if they are identical or have similar features, except for *spatial location*?

- Gestalt Principles
    - establishes a set of rules or orders that are the basic prinicples of how we perceive things
        - Closure
        - Proximity
        - Continuation
        - Figure + Ground
        - Similarity
    - these principles all help us recognize objects, by grouping and understanding which visual elements go together to form objects in our vision. They also help construct illusions by playing on these principles.
- Object Constancies is the principle that we can continuously recognize objects despite large changes in an object’s key features.
    - a Pink elephant for example, or the differences in viewing angle of objects, or environments. the important part is that, despite those changes like in the environment, we can very easily and quickly see an object for what it is, despite it  having a different angle to us.
- “Bistable images” are those that can be interpreted in multiple ways, like the ‘duck-rabbit’ image, for which your perception of the figure can change, duck or rabbit, based on where you look at, how, and what angle, for example.
- These principles also help us understand and know what objects are even if they are *occluded* or obscured in some way, because our brain ‘completes’ the representation of objects.

- These kinds of principles come from the WHAT pathway, or the **VENTRAL** pathway of visual information processing.
    - early information is processed based on its localized aspects and some low-level properties, raw processing of images for example. further down the pathway, combinations of information help us construct more complex interpretations and representations of the stimuli.
    - object-recognition happens in the **infero-temporal** cortex.
    - image representation is constructed hierarchically, and this is shown through the fact that **receptive fields** are combinations of other receptive fields from regions earlier in the visual pathway.
        - many different RFs from the retinal ganglion cells combine in the LGN to form a single cell, and this happens to many different groups of retinal cells. Those LGN RFs also combine in the V1 to make a larger RF.
        - this even happens from the V1 RFs to the Infero-temporal RFs, which is a good indicator to us that the visual information is constructed as it travels further down the pathway, and integrates with much more information.
    - early-levels of image processing such as line-orientation, and the many RFs that make up a single image is not what we consciously focus on, but rather the later stages of image construction that involve object recognition, because at this point in processing is the arrival of the full object, and not its constituent components.

- V1’s orientation selectivity
    - cells in V1 are *tuned* to respond to specific orientations, and these preferences are organized into *columns* of V1.
    - This was shown to happen in cats via Hubel and Wiesel’s research
        - their research was confusingly complicated as they were single-cell recording in cats, but no stimulus they showed would trigger a response in the cell, until they accidentally discovered by removing the slide from the projector, that the neuron would fire in response to particular orientations of lines.
    - even cells in V5 (medial temporal cortex) are organized in columns, and are sensitive to motion

- Complex preferences in the anterior IT
    - further down the processing pathway, there are more complex stimuli that cause neurons to activate more, like specific orientations of hands, and as the detail of the hand goes down, so does the response of the neuron, as the hand becomes more ‘abstract’
    - V4 and V8 show sensitivity to color
    - LOC (lateral occipital cortex), sensitivity to form
    - V5, motion
    - Anterior inferior temporal cortex, shows preferences to *object classes*.

- Receptive Field size
    - cell density is highest at the **fovea** for all areas
        - this is a reason why we *foveate* objects (center them in the visual field) to process them better.
    - RF size becomes *larger* the further we move away from the fovea
    - RF size increases as we move further along the *ventral* stream
        - these two points encompass the idea that single objects can become represented in a single RF because in the further away areas down the stream, the cells become bigger.
    - in the dorsal stream, only 60% of RF cells are meant for the fovea.
        - this leads us to understand that the ventral field is more based on the center of the visual field - the fovea - where we focus on single objects for understanding and constructing that object, whereas the dorsal stream is responsible more for the periphery of vision.
    - Inferior Temporal (IT) cells always include the fovea
    - these larger sizes of receptive fields in the inferior-temporal cortex allows neurons to respond to objects regardless of spatial location or size, and are great for being able to capture the **global shape** of an object, rather than just its discrete local features

- Synesthesia
    - occludes the idea that visual processing is modular, that discrete pieces of vision are broken up and processed by different regions
    - synesthesia is a multi-sensory experience from a *single percept*
        - often times, you experience other sensations and perceptions from a single channel, like numbers being associated with coors, months have a *spatial location* to them, or the ability to *taste* colors.
    - the most common form of synesthesia is *grapheme-color* in which numbers are experienced as colors.
    - some people with synesthesia have better memory recall for black and color-congruent stimuli, possibly because this extra-information about stimuli can be better processed and remembered for recall in terms of memory.
    - not much is known about *why* synesthesia happens, but there are some ideas that:
        - synesthesia occurs because of cross-linkages between brain regions, possibly due to dendritic pruning (when younger)
        - OR, that *re-entrant activation* occurs, due to much stronger back-projections to posterior regions that are involved in certain regions such as color, space, etc. and this re-entrance of information happens when synesthetes perform object recognition.
    - Alexander Luria had a patient “S” in the 1960s who had a very strong synesthetic experience, attributing numbers to colors, and also personality & character to numbers as well. this patient was also very strong in terms of memory

![Ventral stream of visual processing](repo/wlu/psychology/neuropsychology/PS365/PS365%20-%20Neuropsychology%20fddaf3f488c24206b552caf5d20511b7/Object%20Recognition%20494b84af3824448eaeb19a0216b2a082/Untitled.png)

Ventral stream of visual processing

![Receptive Fields construct larger RFs down the pathway of processing](repo/wlu/psychology/neuropsychology/PS365/PS365%20-%20Neuropsychology%20fddaf3f488c24206b552caf5d20511b7/Object%20Recognition%20494b84af3824448eaeb19a0216b2a082/Untitled%201.png)

Receptive Fields construct larger RFs down the pathway of processing

![Organization of orientation biased cells in the V1](repo/wlu/psychology/neuropsychology/PS365/PS365%20-%20Neuropsychology%20fddaf3f488c24206b552caf5d20511b7/Object%20Recognition%20494b84af3824448eaeb19a0216b2a082/Untitled%202.png)

Organization of orientation biased cells in the V1

![Neuron responses in higher-order visual processing in Anterior IT](repo/wlu/psychology/neuropsychology/PS365/PS365%20-%20Neuropsychology%20fddaf3f488c24206b552caf5d20511b7/Object%20Recognition%20494b84af3824448eaeb19a0216b2a082/Untitled%203.png)

Neuron responses in higher-order visual processing in Anterior IT

![Untitled](repo/wlu/psychology/neuropsychology/PS365/PS365%20-%20Neuropsychology%20fddaf3f488c24206b552caf5d20511b7/Object%20Recognition%20494b84af3824448eaeb19a0216b2a082/Untitled%204.png)

![Representation of approximate RF sizes based on the regions of visual processing (based on monkey neurophysiology)](repo/wlu/psychology/neuropsychology/PS365/PS365%20-%20Neuropsychology%20fddaf3f488c24206b552caf5d20511b7/Object%20Recognition%20494b84af3824448eaeb19a0216b2a082/Untitled%205.png)

Representation of approximate RF sizes based on the regions of visual processing (based on monkey neurophysiology)

- View Dependent vs. View In-dependent
    - view dependent theories are based highly on memory
        - the “idea” or the “concept” of the bike is called upon, as a template of sorts, of which we can understand and grasp and know each angle that is possible.
    - whereas view-invariant theories are based around the idea that sensory input describes the basic properties of objects, to which other properties are relation (Marr’s computational theory)
        - the concept relies on the fact that low-level computation of vision relies on processing basic information, such as the axis of an object (the principle axis) and other various axes, based on perspective.
    - Biederman proposed that objects are defined by combinations of parts**,** which are called “geons”, that form a *perceptual alphabet*, and objects are defined by a unique set and arrangement of geons.
        - however, this has some holes in the fact that we can recognize two of the same *types* of objects, which have completely different geon-makeups. Or, are able to distinguish between different objects with very similar geon constructions.
    - The **Hierarchical Theory** is based on the “grandmother cell”
        - where discrete components of objects are recognized in terms of the hierarchical make up of it, like in this “table cell” example.
        - this is not exactly reliable, as any brain damage in these cellular regions would result in catastrophic deficiencies in object recognition, which is not the case, as seen in various forms of agnosia, where the object-recognition faculties are pretty resiliant to brain damage.
        - final percepts would be coded into single-cells, which is not something we have seen neuroanatomically
        - and what about new objects? how would be even begin to construct them without the necessary cells already there?
    - **Ensemble Encoding** is a different take on how we build things hierarchically, instead of having discrete cells for specific objects, which is pretty ridiculous, we rather understand single objects or people or things as *combinations* of features, an ensemble if you will.
        - for example, your grandmother has distinct features that make her up, along with class of other people like her. such as face shape, accessories, unique features based on your grandmother.

- Visual Agnosia
    - “Agnosia” = a “without” + gnosis “knowledge” = “without knowldge”
        - Apperceptive agnosia is the impairment of *object recognition* due to *degraded perceptual abilities*
        - Associative Agnosia is the impairment of *object recognition* despite the *intact perceptual processing*
            - people with associative agnosia can, unlike apperceptive agnostics, copy and match objects well based on an image, but have a lot of trouble drawing from memory (the exact opposite of apperceptives), because they have a hard time attaching labels or names to objects.
            - this condition is associated with brain damage further along the processing stream, typically the occipito-temporal border, or even in the temporal lobes.
                - most often in bilateral damage, but also in unilateral-left hemi. damage as well
            - the difficulty in attaching semantic knowledge of objects to their perception of those objects
            - it has been seen to affect specific *classes* of objects, which is most common for the categories of “living” and “non-living” objects.
                - this may be because artificial tools and man-made objects have less in common than living things do, so living things could be represented in common neural networks. this is why artificial object-recognition can be more stronger even in those with associative agnosia.
                - there may be an evolutionary reasons why this occurs, because of the uses of being able to practically differentiate objects like animals vs. things that are inanimate.
                - living things are also “homomorphic” in which they have similar shapes throughout species, have organic forms, and have features like heads, tails, limbs, etc.
                - tools and inanimates are also defined by functional attributes, like what they are for and how we use them, but this cannot be said for animals
                    - which is why they are more resistant to categorical agnosia
                - a patient of U Waterloo had agnosia for specific classes of musical instruments, for string instruments, but not brass instruments.
                    - this leads us to the idea of a “psychological neighbourhood” of objects which share multiple characteristics.
        - A common type of agnosia is **prosopagnosia**, which is the inability to distinguish between faces, but they are recognized as faces.
            - Some interesting properties are that the *sex* or *relative age* can be determined still, and patients with prosopag. can still distinguish and recognize people through other senses, such as voice, etc.
            - This shows that low-level concepts like sex or age are different from semantic things like the identity of a face.

- Are faces special??
    - Prosopagnosia has prompted the idea that faces are very important in terms of visual processing.
    - Faces are the most salient and useful featured that is used to identify people and distinguish them, and social information is mostly conveyed through facial expressions.
        - which are suprisingly universal, despite culture, ethnicity.
    - the face-inversion effect is something that lets us clue into the fact that faces are not processed exactly feature-by-feature, but rather as a whole.
        - upside-down faces, where the eyes and mouth are inverted to be right-side-up look fine, but look awfully bad when the face is turned right-side-up again, and the eyes and mouth are inverted.
            - this kind of shows the bias we have to processing upright faces vs. upside-down faces.
    - This is called “Holistic processing” and is shown much better when asked to recognize faces vs. objects
        - when only *parts* of the stimlu are presented as recall information, its much harder to recall faces than it is non-face stimuli.

- Right hemisphere and faces
    - the left-visual field has an advantage for faces, because the right-hemisphere has an important region for faces called the **fusiform gyrus**.
        - however, this area does not only respond to faces, it responds to objects as well, but faces yield the *strongest* activation
    - lesions in the right-hemisphere showed an impairment in facial recognition, but a reduced inversion effect, and there is fMRI evidence to support that the right-hemisphere’s fusiform gyrus is more prominent than the left-hemisphere
    - is this fusiform gyrus hinging on the familiarity we have with objects like faces?
        - it has been shown previously that facial memory recognition is much stronger than verbal memory recognition
        - the “Greebles” study had some interesting results where participants were trained to recognize the differences in these Greebles, and that the prior training and experience with Greebles showed significant fusiform activation compared to people that were totally unfamiliar with the Greebles.
            
            ![Untitled](repo/wlu/psychology/neuropsychology/PS365/PS365%20-%20Neuropsychology%20fddaf3f488c24206b552caf5d20511b7/Object%20Recognition%20494b84af3824448eaeb19a0216b2a082/Untitled%206.png)
            
        - This function of the fusiform gyrus can activate in many different stimuli, but the common connection is that activation occurs extensively in those are extremely familiar with certain classes of objects.
            - like activation in response to vintage cars for experts in cars, dogs in dog judges, etc.
            - 

![Untitled](repo/wlu/psychology/neuropsychology/PS365/PS365%20-%20Neuropsychology%20fddaf3f488c24206b552caf5d20511b7/Object%20Recognition%20494b84af3824448eaeb19a0216b2a082/Untitled%207.png)

# Article

**Tripartite Organization of the Ventral Stream by Animacy and Object Size**

---

- the organization of object recogniation in columns or clusters can lead to categories of objects, such as animate vs. inanimate.

- this study looks at:
    - animacy
        - because this is a dissociation of things that we can socially interact with vs. manipulate.
            - inanimate things are meant for doing things with them; ie. you sit in a chair
    - size
        - this dissociates manipulation vs. support
- they predicted that this 2D relationship would be projected onto the cortex

- 240 unique images of big + small animals, and big + small objects
    - images presented for 800ms, with an attention check
    - they used some regions of interest relevant to object perception and recognition

![Untitled](repo/wlu/psychology/neuropsychology/PS365/PS365%20-%20Neuropsychology%20fddaf3f488c24206b552caf5d20511b7/Object%20Recognition%20494b84af3824448eaeb19a0216b2a082/Untitled%208.png)

 → They saw that these preference maps are not arbitrary, but are spatially segregated in the cortex

![Untitled](repo/wlu/psychology/neuropsychology/PS365/PS365%20-%20Neuropsychology%20fddaf3f488c24206b552caf5d20511b7/Object%20Recognition%20494b84af3824448eaeb19a0216b2a082/Untitled%209.png)

→ Also that there were big differences in response on *THREE* categories, not 4. We can see that big and small animals have similar response profiles.

A summary of these findings is that size really only applies to the *inanimate domain*, but not a major factor in distinguishing neural responses to different animals.

- because size determines how we interact with objects and tools, but not for animals, since animals can be dangerous regardless of its size.

Tripartite organization may reflect the differences in behavioural affordances of big/small objects, and animals

→ there is an overlap between faces and bodies, and animals; and scenes and big objects.

![Untitled](repo/wlu/psychology/neuropsychology/PS365/PS365%20-%20Neuropsychology%20fddaf3f488c24206b552caf5d20511b7/Object%20Recognition%20494b84af3824448eaeb19a0216b2a082/Untitled%2010.png)

![Untitled](repo/wlu/psychology/neuropsychology/PS365/PS365%20-%20Neuropsychology%20fddaf3f488c24206b552caf5d20511b7/Object%20Recognition%20494b84af3824448eaeb19a0216b2a082/Untitled%2011.png)