# Towards a Real-time Measure of the Perception of Anthropomorphism in Human-Robot Interaction

---

### Due January 26th via Dropbox

# Notes

<aside>
üí° Prosody: Rhythm, stress, and intonation of speech (important speech information)

</aside>

*DEFINE keywords (acoustic-prosody, entrain, uncanny valley, Godspeed Questionnaire, )

<aside>
üí° Anthropomorphism

attribution of human characteristics/behavior to an object, animal, god, etc. (in this case, a robot tutor)

</aside>

[Godspeed Questionnaire Meta-study](https://ieeexplore.ieee.org/document/7333568) ‚Üí [http://gaips.inesc-id.pt/emote/wp-content/uploads/2016/04/Godspeed.pdf](http://gaips.inesc-id.pt/emote/wp-content/uploads/2016/04/Godspeed.pdf)

<aside>
üí° Entrainment ([https://www.sciencedirect.com/science/article/abs/pii/S016763931930086X](https://www.sciencedirect.com/science/article/abs/pii/S016763931930086X))

The tendency of conversation partners to adjust to each other to become similar,

[http://www.cs.columbia.edu/~rlevitan/papers/IS11full_paper.pdf](http://www.cs.columbia.edu/~rlevitan/papers/IS11full_paper.pdf) defines well the different metrics of Acoustic-Prosodic entrainment

</aside>

Summary

---

Essentially, this paper examines the conditions of robot vs. human tutors and how the participants *entrain* to them. This ‚Äúentrainment‚Äù is a measure of the change and degree of speech coordination between people, which is similar to a measure in how ‚Äúonboard‚Äù a participant might be to a potential tutor. There are various studies before this one that examine specifically acoustic-prosodic entrainment of humans to robots, some considering only robotic voices and human voices, other studies try to dive deeper into the social interactions of humans and robots, like how social bonding within interactions works between human and robot interactors.

The broader goal of this paper is to help understand the factors at play with human-robot interaction, as to help further what is needed of robot technology to better mimic the ability of humans. 

An essential, key idea to this study is that humans adapt their prosody (intonation, stress, tempo, rhythm, pause, etc.) to others within conversations, and has been shown to be an indicator of conversational involvement and interaction quality (taken from the introduction). While other studies have examined voice, and interaction, between humans and robots and the resulting acoustic-prosodic factors, this study in particular looks at the conditions of human vs. robot animations, and particularly the facial features of conversation.

More specifically, we want to assess the unconscious entrainment of participant‚Äôs speech interactions with the robot, as well as understanding how each participant would rate the human AND the robot based on how *animate* they are (lifelike, organic, interactive and alive) and how *anthropomorphic* they are (humanlike, conscious, elegant, etc.), and then compare how interested participants are in their conscious perception of the human-human and human-robot interactions.

Their research question is about how the facial embodiment of a conversational agent influences the entrainment of the person that it interacts with, which essentially means how involved and how the participants become based on how the instructor looks when we are considering human vs. robot features.

As a result, they have TWO hypotheses, that human appearance of tutor will incite MORE acoustic-prosodic entrainment, and the second being perceived ANTHROPOMORPHISM of the tutor will positively correlate with the participant‚Äôs acoustic-prosodic entrainment.

‚Üí ie. that participants will become more entrained to the human tutor vs. the robot tutor, and the anthropomorphism rating will correlate with the degree of that entrainment.

Their methods rely on TWO conditions, human and robot conditions, where each tutor will virtually hold a virtual lessons on three random topics and participants is encouraged in engaging with the lesson, asking questions. The way they accomplished having only controlled what the tutor looks like (human vs. robot), is they had a human tutor train a Furhat robot using the tutor‚Äôs facial features, essentially creating a human-robot facial clone of the tutor. The voice stayed the same, since they re-used the audio from the human-based recording, and every variable such as the lesson content, and the post-questionnaire remained the same.

The experimental set-up involved first the lesson, in which participants engaged in the lesson and the content, and after the whole lesson, participants did a questionnaire that included Godspeed questions (about human-robot qualities such as animacy and anthropomorphism, and two other questions about how smooth the social interactions were between videos, and how interesting the lessons were.

They proceeded to use 43 of 51 participant data in an analysis, where they measured prosodic features like (mean/max intensity, mean/max pitch). The data was pre-processed to standardize and remove gaps in speaking (using KNN regression).

They measured *acoustic-prosodic* metrics by computing the **proximity** (similarity of features, how close they are), **convergence** (proximity over time), and **synchrony** (adjusting speech in accordance with the other/ not matching it).

What they found was that:

1. animacy & anthro. scores were sig. higher in human condition
2. interest & smoothness. insignificantly different between conditions
3. all participants entrained on the tutor‚Äôs VOICE
4. the mean pitch (major predictor of acoustic-prosodic entrainment) was sig. lower in robot condition
5. convergence of mean pitch was sig. positive for 65% in human, while 39% in robot condition. (confirms H1)
6. perception of anthro. positively correlated with convergence by mean pitch (leads more to confirm H2)
    1. although entrainment appeared in both conditions, the convergence + synchrony (by intensity) were insig. different between conditions.
7. perception of animacy positively correlated with convergence by mean pitch 

Overall, they seem to have confirmed both hypotheses, that humans entrain better to real humans than robots, and that the mean pitch as the best predictor of entrainment correlated with the perception of human-likeness. This study is not flawless, and has some extraneous variables in the form of participant variability in English speaking, in which participants had different levels of English speaking, accepts, genders, ages, etc. which have been found to affect entrainment.

These results match similar studies about human-robot interaction, that humans entrain less to things that are less-human, like robot voices, etc. Our expertise and involvement in human-human conversations might be due to things found in other studies, such as how ‚Äútrustworthy‚Äù and how ‚Äúsocially present‚Äù the other person in conversation may seem.

At the end of the paper, the researchers go into linking how we perceive anthropomorphism and how we entrain based on mirror neuron activations (which activates when humans observe/interact with other humans). These neurons are entirely imitation neurons that activate when observing other humans, as to ‚Äúmirror‚Äù their actions and in a way, step into their shoes via neurons: ‚Äúwhat would activations looks like if I did that same action?‚Äù. The fact that we have these mirror neuron activations may be something that is key to human-robot social interaction, since humans have many ways observe and understand whether something is human or not.

---

‚Üí Something this paper touches on is the ‚ÄúUncanny Valley‚Äù of robot human-likeness, and how it contradicts research on how we behave to things that are more human-like. However, it fails to take into consideration the fact that it is more subjective than objective in terms of ‚Äúlikeability‚Äù. There are many examples of robots attempting to be more human-like, and attain many more qualitative features in the face, but start to fail with how likeable they are. 

DO MORE RESEARCH ON THE UNCANNY VALLEY

‚Üí The truth is that humans are entirely and unequivocally experts on humans.

# Script & Structure

- INTRODUCTION
    - Hello, I‚Äôm Darko and I will be breaking down this paper from Hauptmann, called ‚ÄúTowards a Real-time measure of the perception of Anthropomorphism in Human-Robot Interaction‚Äù. This title is for-sure a mouthful, but that‚Äôs what I‚Äôm here for. A very brief explanation of this paper is that they are trying to measure the differences in human and robot social engagement. For example, think about times you‚Äôve had to deal with anything that is a *robot* in any sense of the word, an automated system, robotic voice systems for banks and tellers, those bot-like chat windows that open when you visit most websites.
    - Let‚Äôs quickly define the origins of robots, and what we started buildig them for. Early on, even by the 4th century before christ, people were thinking about mechanical creations that worked on steam, and eventually, early engineers started building those complex things like clocks to keep time for a whole village or city, water wheels to automatically turn shafts and transfer that rotational force into a linear one, which all eventually blew up into the industrial revolution, where machines did a lot of our work for us. things became possible that weren‚Äôt before, like running factories much faster and longer, and requiring less trained people to do so. Da Vinci was one of the first to prototype the first *humanoid* automaton, and Descartes essentially said that animals are mechanical machines. Humans are notorious for essentially wanting to replace ourselves from doing work, so that became more of a possibility once computers evolved. That‚Äôs partially my biggest interest and why I‚Äôm also a computer science major, because once the thinkers of the world discovered that the human nervous system is a big, organic computer, then it become much less jarring to think that we may one day construct an automaton of electricity, just like us, that can do what we do. Hardware advancements make it possible to make physical, moving robots with servos and motors, while software robots work as their brains. Computers are also now used to build models and emulate brain function and help understand the brain from a computational perspective. More complex models have started to borrow ideas from psychology like the neural networks, that allow AI programs to learn how to do tasks, like identify numbers or images, when you train them on those images. However, these are more theoretical, and it‚Äôs not very simple, easy, or cost-effective to create machine-learning models for most things yet, because training them takes millions of data points and thousands of real-time hours. It‚Äôs like in those science-fiction movies where the rogue AI googles about what humans do and learns about them, and then eventually hates them. That is something that is computationally really difficult, so the modern robots are limited to being very simple if-else-then structured robots, that have only a finite amount of combinations of options to choose from.
    - That‚Äôs why robots and automated systems are everywhere, because they are very efficient and they require less work overall to just implement some industry-level robotic system for a service that you want to make automatic. As long as you‚Äôre not making the robot yourself and programming all of its behaviors, it‚Äôs much less work than having a 24/7 support system of REAL humans. However, you can‚Äôt automate *everything,* because there‚Äôs a fine-line between good and bad automation. Most people become easily frustrated by these automated support systems, because as technology gets more and more complex, we get better at solving the smaller issues as a population, so we need to call tech-support only for these more complex, service-dependent issues because we can troubleshoot on our own, and don‚Äôt need a robot listing off the ‚Äúhave you powered it off and on again‚Äù. In fact, a NY Times article has some good insight as to why tech-support is purposely frustrating in some circumstances, like having a lack of competition in the respective market. Cable, phone, and internet providers are notoriously monopolized, and a lot of people hate their automatic customer service, but there‚Äôs a lot of good customer service out there for markets which have great competition, because customer service can set them apart. If you had a bad experience with customer service, you can just ... go to another competitor and that‚Äôs a huge reason why most people switch their services if they can.
    - However, I digress, and I hope you understand what I mean by social interactions and robots, it‚Äôs typically very difficult to *warm up to* a robot or automated system, because they are ... automated. They are programmed and have a set of responses that only changes based on what you answer with, and does not do human things like make jokes, or small talk. Most importantly, robots don‚Äôt *sound* human. Text-to-speech technology has come A LONG way, but really good synthesized voices require thousands and thousands of different clean and high-quality audio files of a single person‚Äôs voice to even begin to remotely sound like them, and that only really sounds good for that one, unique voice. Take this for instance, here‚Äôs an iconic Dr. Phil moment ... and here‚Äôs what I synthesized from a free, community-based AI engine called UberDuck based on someone‚Äôs Dr. Phil model. It‚Äôs pretty good, but it‚Äôs definitely not perfect.
        - There‚Äôs something very important here to notice that can be quite subtle if you don‚Äôt know what it is: the pacing of the speech. This leads me into my next segue of some of the variables that this paper is looking into.
    - To start off with understanding what this paper aims to do, and what it has shown, it‚Äôs very important to understand exactly what it is measuring. First off, let‚Äôs begin very basically with understanding what **prosody** means in terms of speech and social interactions. Prosody is defined as the structure of discrete tonal elements, in conjunction with the sentence structure [Prosody and language comprehension]. Basically, it‚Äôs the rhythm, stress, and intonation of speech that gives you the important context clues and social cues of what is meant by spoken words than just the literal meaning of the words themselves.
        - For example, the sentence ‚ÄúI didn‚Äôt do it‚Äù can have many different implications based on how you say it, and what word you emphasize. ‚ÄúI didn‚Äôt do it‚Äù, ‚Äúi DIDN‚ÄôT do it‚Äù, ‚Äúi didn‚Äôt DO it‚Äù, ‚Äúi didn‚Äôt do IT‚Äù
    - These are all very subtle difference that can be very difficult to pick up if you‚Äôre not a  paying attention to them. However, the main point is that these differences entirely depend on the context of the situation, and the agents involved in conversation. Especially when you are trying to do things like get to know someone, and work with them
        - [Acoustic-Prosodic entrainment and rapport in collaborative learning dialogues].
        - This is something that robots simply cannot do right now, because it is so nuanced in context, only the most advanced robots just barely manage to do, but even then, they are not as skilled as we are as human in interpreting when to speak, what to say, and how to say it to get across a goal or a meaning with what you say. I can‚Äôt even imagine how I would begin to program a robotic voice, that says something and means the complete opposite, and conveys this opposite through its prosody in speech, like in the case of sarcasm.
    - Let‚Äôs move on and tackle what it means to be anthropomorphic. The dictionary definition of anthropomorphism is: ‚Äúthe attribution of human characteristics or behavior to god, animal, or object. This is something we do to our animals, by giving them voices or thoughts, or human emotions. This paper however, interprets anthropomorphism to mean more ‚Äúhuman-like‚Äù, specifically in appearance. There‚Äôs a lot to be said about non-human things looking like humans, and there are a lot of examples of depictions of humans, horiffic ones, and great ones. Human-like anthropomorphic depictions are everywhere, even in things that are non-human in nature, like with animals. Animated media and cartoons with animals, have a very human-like nature to them, mostly because they often talk, are bi-pedal, and have complex relationships with characters, etc. These animals aren‚Äôt human obviously, but their degree of anthropomorphism helps us relate to them more. There are many studies concerning how we can relate to things based on their human-like qualities. One in particular, by Crowell, manipulated the degree of anthropomorphism in robots, and how autonomous it appeared. They saw that participants were unwilling to anthropomorphize the more-human-like robot, but did so when they though the robot was controlled by a human [Automorphism of Robots]. This is a very weird and unexpected behavior to me, because you would think that more-human-like robots would be more welcoming. However, there‚Äôs a large phenomenon called the Uncanny Valley, which applies to human-like things, this graph perfectly illustrates what it means to be in the uncanny valley. It‚Äôs quite a subjective measure to be frank, but the idea is illustrated well. Take a look at some of these pictures of robots and tell me that you wouldn‚Äôt be afraid to be locked in a room with one of them.
    - Human facial appearance is extremely difficult to emulate, because, just like speech, there are so many variables and individual differences, that makes it too difficult to model a real human, without a real human, and only using synthetic materials. Human skin has a lot of different qualities to it, that depend entirely on the person. Some people have dry skin, some oily, some have even oily and dry skin, in different areas. There is also an organic system of blood, sinus, flesh, bone, and thousands of muscles that power facial expressions, which are all tied together. The lighting and texture of skin is impossibly difficult to describe, it has something called ‚Äúsubsurface scattering‚Äù as light can penetrate and scatter in the skin. The fact of the matter, is that, as humans, we are undeniably the experts in terms of identifying other humans. Our wrinkly brains have even developed areas like the Fusiform Gyrus that have been seen to specialize in object and face recognition.
    - This is not to say that making realistic faces through computation is impossible however, because advanced machine learning models like Generative Adversarial Networks (GAN for short), can construct faces extremely well and realistically. check out [thispersondoesnotexist.com](http://thispersondoesnotexist.com) if you ever want to see it for yourself. This limitation really only exists in functional, physical robots. Unfortunately, I don‚Äôt think that Ridley Scott‚Äôs vision of Blade Runner is something that will be attainable in the near future.
    - Robots may be eternally trapped in this uncanny valley if they decide to keep making life-like robots. Some robots take a better route, and decide to make it uniquely robot, so that we can anthropomorphize it ourselves, and have better interactions with them. Take for example, Wall-E from the movie, or those new food delivery robots in Toronto, or Japanese robots. They take a more characterized approach, kind of a ‚Äòneutral‚Äô design.
    - So let‚Äôs keep tackling what this means for the paper. All of this information combined together can help us understand what the purpose of Acoustic-Prosodic entrainment is. To define this entrainment, it is the tendency of communicating agents to adjust the prosody and speaking styles of themselves to become more similar in to the other in conversation. When you or I converse with each other, how we speak depends on each other‚Äôs speaking styles, and a lot of the background research surrounding the paper itself goes into detail about how we entrain to each other, and to robots with different qualities.
    - Let‚Äôs examine in detail the background literature of this paper, and understand what results it‚Äôs trying to leverage to make its point clear. To start off, we have some supporting evidence from Tickle-Degnen and Rosenthal‚Äôs [The Nature of Rapport and its nonverbal correlates] that in order to manifest a sense of rapport or bonding in someone else, that there exists many non-verbal qualities of social interactions that we require alongside their words. For example, the experience of mutual attentiveness and positivity are weighed more heavily in the first, initial interactions you have someone. That is, how positive the interaction was, and how attentive you are to the interaction, and how attentive you perceive them to be. This is a topic that is very important to think about when you are trying to have participants have good experiences and enjoy the company of the robot specifically, we need to build the model robot such that it can accomplish these things, otherwise, it‚Äôs doomed to fail when trying to have some influence over people.
        - To continue, we have many different papers explaining the importance of the acoustic-prosodic entrainment as well. In terms of interactions between humans, the amount of rapport you have with someone is related the the acoustic-prosodic entrainment that happens in a conversation. A paper by Lubold and Pon-Barry saw this explicitly, that rapport is influenced by how we entrain to eachother in conversation, and that the pitch of prosody helps entrain people when rapport is already present.
        - Acoustic-Prosodic entrainment is also correlated to how involved we become in a conversation and the quality of interactions, which is shown by two different groups of researchers, Looze et. al, and Reichel et. al. Overall, this is something that is really important for how we involve ourselves with robots in everyday life, because robots who lack the ability to entrain to us, and vice versa, will also lead to bad interactions and generally less-willing participants to care about the robot and what it has to offer. With this being said, would you be more likely to have a good experience with a robot that does not address you directly? Sometimes we might not even notice it, but that is an essential part of human-human conversation, to know who we are speaking with and addressing them more personally than generally. Luckily, there are also studies and advancements in technology that allow robots to be aware of their audience, and allow them to integrate automatic attentiveness to whoever is speaking, and the ability to address participants seperately.
        - The Hauptmann paper itself goes into detail about how the uncanny valley affects robots specifically, and points out that, unlike the previous exmaple of automorphism of robots, that human-like robots tend to increase trust-worthiness, and social presence, which is unexpected. In fact, this is part of the primary research question of the paper in question, as they are looking to understand specifically how humans and robots entrain based on the degree of anthropomorphism and how this influences the behaviour of the user.
        - The importance of understanding how entrainment is crucial to learning in specific has also been explored by researchers who saw that acoustic-prosodic entrainment is indeed necessary to improve understanding of taught information. A seperate paper details that anthropomorphism can also aid in memorisation of learned information. Hauptmann then indeed explores the relationship between these two, by manipulating the degree of anthropomorphism, and uses acoustic-prosodic information to tie into this degree of anthropomorphism. Essentially, if entrainment with speech has affects on learning, and so does the degree of anthropomorphism as seen by other papers, how does anthropmorphism affect entrainment?
        - This research question is something that needed to be studied to understand the optimization that‚Äôs needed in current robot models, to deliver better socially operating robots that can help as social agents. The robots seen today lack a lot of qualities, but this paper aims to understand the non-literal or non-obvious cues that are necessary to do so. Based on the previous background literature, they hypothesized that participants will entrain better towards a human face rather than the robot, and also that the degree of entrainment will correlate with the perception of anthropomorphism they experience.

- METHODS and TASKS
    - This paper uses a remote-setting over Zoom meetings to conduct the experimental tasks, and the essence of the main task is that participants will be tutored over Zoom on three random, unrelated topics. Instead of testing for the amount of information that is learned or memorized, they are paying attention to the participant‚Äôs interactions with the instructor for acoustic-prosodic entrainment. These lessons were pre-recorded videos, and were the source of the conditions, which were a **human** instructor, or a **robot** instructor, and each lesson was about 10 minutes in total. It‚Äôs important to know that the pre-recorded videos were *pieced-together* during the experiment using videos of idle states of each instructor, so that it seemed like a continguous lesson, and to keep the flow of conversation so as to not interrupt people participating.
    - Because the dependent variable being the entrainment of participants, they were encouraged to verbally interact with the instructor
        - One thing that is NOT mentioned in the paper however, is how participants received an answer to their question or interaction. We don‚Äôt know if their questions were answered at all, or if someone answered them live, or they had generic, umbrella answers pre-recorded.
    - The participants were split into two conditions randomly, which were rigid, and involved a *human* condition, and a *robot* condition. This meant that in the human condition, a real human tutor relayed lesson information, while in the robot condition, a robot did. The main connection between these conditions is the fact that they used a *social robot* called a Furhat, with the tutor‚Äôs synethsized face. Essentially this means that they re-created the human tutor‚Äôs face onto the robot, and they also analyzed the human tutor‚Äôs facial movements, and put them into the robot so the robot could feel a like more like a robot-clone of the human tutor.
        - Here‚Äôs a Furhat that I actually programmed using the official SDK I got from the same company. You can see here that this is an extremely primitive model in comparison to theirs. I would‚Äôve mapped my face onto this Furhat, but it got a little complicated and eventually wanted to save scarring myself by hearing and seeing a robot-clone of myself. On the right, you can see that this is the code that it runs, in its most basic form. There are a lot more options this robot has, and some of the advantages this Furhat brings in comparison to other robots is that it pays attention to the amount of attendees, their names. Something special as well, is that this robot comes in a physical form, just as a bust of its face, and is able to physically rotate towards people who it is paying attention to. Honestly a little creepy, but when it is given a sophisticated program like the one in the paper, it can be pretty convincing.
    - Partipants also completed a questionnaire after the entire 3-topic lesson, and the questions were based on another called the Godspeed Questionnaire, which was constructed to be a great inventory of human-robot interaction qualities, the specific ones used were about **animacy**, and **anthropomorphism**. Two other questions were present to be able to control for the conditions and participant experience overall, which were scores on how **interesting** the lessons were, and how smooth lesson-transitions were (in order to understand any other differences in conditions other than the independent variable, the tutors, and the novelty of the robot itself)
    - Overall, the methods are simple and quick and are meant to emphasize the differences between human-human interactions and human-robot interactions, primarily through the degree of involvement and entrainment participants were willing to show.

- RESULTS
    - In total, there were 51 english-speaking participants, with only 43 of them being included in the results because of internet and recording issues. The analysis of the data of these 43 participants included analyzing their interactions between conditions. However, it was important to first process the speech data by eliminating silence and noise through K-Nearest-Neighbours regression. This speech data contained 4 very important qualities about speech that were extracted, mean and max intensity of speech, and the mean and max pitch.
        - This being entirely dependent on the speech of the participant however, means that the quality of audio is important. However, Hauptmann was not able to control for the differences in microphone qualities and therefore background noise levels in individual participants.
    - Using the measurements of prosody such as mean and max intesities and pitch from participants, they applied furher functional processing to those measures to calculate the three main components of acoustic-prosodic entrainment, called
        - Proximity, Convergence, Synchrony
            - Proximity is the negative-absolute difference in each of those 4 features (mean/max intensity/pitch) at each point in time. Essentially, how *close in proximity* is the participant‚Äôs feature to the instructor. It‚Äôs pretty important to know as well that because of differences in the sound of voices for males vs. females for example, they took the z-score of the features to standardize them, then applied the functions.
            - Convergence is a measure of proximity *over time*, so a positive convergence means that proximity increases over time, whereas negative means that they become *less similar* over time.
            - Synchrony is a measure of how each participant matches their features to suit the features of the tutor of the condition.
    - What they found through their results was that:
        - animacy and anthropomorphism scores were *significantly higher* in human condition
        - interest and smoothness scores were insignificantly different,
            - which means that the conditions were similar in how they were conducted, in terms of content and how technical they were.
        - in both conditions, the participants entrained on the tutor because they had a high synchrony in entrainment.
        - however, the mean pitch of prosody features was significantly lower in the robot condition, and convergence to the mean pitch was significantly positive for the human condition for 65% of participants, but 39% in the robot condition.
            - the mean pitch is the major predictory of entrainment, so this means that entrainment was stronger in the human condition, which confirms their hypotheses that humans will entrain better to the human tutor, and combined with the fact that  the rating of anthropomorpism was higher in the human condition, it correlates entrainment with anthropomorphism.

- Discussion and Conclusion
    - based on their results, Hauptmann has related the concepts of acoustic-prosodic entrainment in conversation with the perception of anthropomorphism, and found that human participants did entrain better to the human tutor, and that is correlated with the degree of anthropomorphism involved.
    - This study‚Äôs findings are entirely based on the qualities of the Furhat robot they created, and the qualities they borrowed from the human tutor to create his robot replica. For example, the results may be entirely different if they had used a different variety of socially-attentive robot, or had used a cartoon-like robot instead. Perhaps in the future, with more sophisticated software and advanced facial-combinatory-technology that uses ultra-realistic synthesized human faces, we may see a different outcome than we do here.
    - This study is quite similar to another, but expands the paradigm to include visual detection of anthropomorphism, a study by Thomason, Nguyen, and Fischer measured the influence on differences in human-robot voices instead of facial expressions, and saw a similar outcome, that human voices entrained more than robot voices.
    - An exaplanation in terms of neural anatomy of perception may involve mirror neurons, since those neurons are uniquely dedicated to understand and learn through modelling and observing other humans. Quite possibly, as experts of human identification and recognition, this paradigm of human-robot interaction and the degree of entrainment may be mediated by neuro-anatomical functions because of the large differences in human and not-very-human-but-trying-to-be-human robots.
    - Ultimately, this paper understands that its methods limit it to an observation of entrainment to an educational scenario, and does not generalize well to the total degree of difference in human-robot interaction regardless of the task at hand. That being said, this paper is a great step towards understanding how we humans interact differently to humans and robots in the task, and solidly backs up its claims and hypotheses with a simple experimental design.
    - Personally, this is something that, as a computer science student, has always fascinated me. The idea of science fiction come to life, like Blade Runner is something that I both enjoy and disdain. In the current state of the world, I believe that advancements like these are great to understand more about how the future can evolve, and it really is pleasent to know that we are far off from having an overlord computer that can go rogue, or AI that will eventually replace us in the workforce. However much can go wrong, can also go right, and understanding how we can improve on necessary systems to enable things like digital learning will overall enhance the quality of the many things that we currently have in place.
    - Furhat Robotics is actually a very interesting company in terms of what they have shown with their robots. They conducted the Milgram Experiment on these robots, and even hinted at using their robots as unbiased judgements of character and qualifications. Other recent research in this area of entrainment to robots base the paradigm entirely on the robot, as in Mostafaoui‚Äôs research about synchrony in coordination between humans and robots, they found that entrainment is present and that it‚Äôs much stronger when both the robot and the human attempt to adapt to each other. Each experiment is but a baby-step into knowing the limitations of human-robot interaction lies.

# Discussion

- Aside from some clear limitations in terms of Zoom experiments, or the variability in participants, share something that can be improved on in the experimental design.
- The researchers decided to use a *binary* representation of anthropomorphism using the two conditions, human and robot. Could they have introduced more intermediate conditions, with the midpoint being the robot they used?
- Put yourself in the participant‚Äôs positions, having a lesson over Zoom about your university courses. How do you think it would influence your own learning? Would you prefer a real professor, or an AI professor; which possibly in the future, may be able to access databases of information on topics easily, and vocalize and link concepts together.
- What about the real-world scenario, without Zoom meetings. If the participants were tutored by the real Furhat robot in physical form, do you think it would change Hauptmann saw in the results?
- Would the context of application for these robots matter, or would it be the same across different situations?
    - For example, circa 2013 South Korea planned to invest in english-teaching robots for *practice*, but not learning.
- We already have the basics of these kinds of social robots in our homes, Google homes, or Alexas for example. Our phones also had the software technology like Google Assistant or Siri before these home systems, so how many years do you think it will take to integrate this social robot in conjunction with the facial technology we saw into these home systems?
    - While it‚Äôs a bit farfetched, an old Disney Movie called Smart House actually explored these concepts way before, in 1999. The housekeeper ‚ÄúMother‚Äù manifested in a physical, but holographic form.
- Do you think it‚Äôs necessary to give robots friendly faces, if it has a face at all?
- Let‚Äôs get a little more involved in how this might affect clinical or case-studies, where in psychology would friendly, social robots fit in best?
    - Through some research, most of what I could find on ‚Äútherapy robots‚Äù were animals. Putting the cost of realistic robots aside, would it be better to have animal robots or human-like robots?
    - There‚Äôs a variant of baby dolls called ‚ÄúReborn Babies‚Äù which are made with silicone and look extremely realistic. Could this be a possible candidate adding robot capabilities to it?
        - The Guardian‚Äôs video mentioned that one of the collectors that are featured in the video, [https://www.youtube.com/watch?v=yP09Gm5rp9I](https://www.youtube.com/watch?v=yP09Gm5rp9I), cannot have babies herself. This might be a hint at the possibility to give therapy and aid people who are infertile, have had miscarriages, or are grieving.
- What about children‚Äôs toys? I‚Äôve heard from a lot of single-child people that being a single-child was difficult with no siblings, so could realistic toy robots enhance their experience?